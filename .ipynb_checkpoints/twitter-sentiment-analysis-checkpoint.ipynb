{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41675c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the necessary librarires\n",
    "\n",
    "import math\n",
    "import nltk\n",
    "import scipy\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import randint\n",
    "from wordcloud import WordCloud\n",
    "from multiprocessing import Pool\n",
    "from nltk.corpus import stopwords\n",
    "from scipy.stats import loguniform\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV,RepeatedStratifiedKFold,GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import lightgbm as lgb\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score,roc_auc_score, roc_curve, precision_score, recall_score\n",
    "from scikitplot.metrics import plot_roc_curve as auc_roc\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [20,6]\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dcac83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the dataset\n",
    "\n",
    "tweets_df = pd.read_csv('tweet-sentiment-extraction/train.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899c717e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3723735c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.describe(include='O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8503d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.drop(['selected_text', 'textID'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9227afcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcc9810",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'sentiment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67b5f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = tweets_df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368d0248",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n\\033[1mData Dimension:\\033[0m Dataset consists of {} columns & {} records.'.format(tweets_df.shape[1], tweets_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d54d8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the dtypes of all the columns\n",
    "\n",
    "tweets_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b90c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the stats of all the columns\n",
    "\n",
    "tweets_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa9fb75",
   "metadata": {},
   "source": [
    "### 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f351ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for empty elements\n",
    "\n",
    "tweets_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b10669",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the null values\n",
    "tweets_df.dropna(inplace=True)\n",
    "original_df = tweets_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77be803c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df[tweets_df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbea153f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removal of any Duplicate rows (if any)\n",
    "\n",
    "counter = 0\n",
    "r,c = original_df.shape\n",
    "\n",
    "tweets_df_dedup = tweets_df.drop_duplicates()\n",
    "tweets_df_dedup.reset_index(drop=True, inplace=True)\n",
    "\n",
    "if tweets_df_dedup.shape==(r,c):\n",
    "    print('\\n\\033[1mInference:\\033[0m The dataset doesn\\'t have any duplicates')\n",
    "else:\n",
    "    print(f'\\n\\033[1mInference:\\033[0m Number of duplicates dropped/fixed ---> {r-tweets_df_dedup.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fbd77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df_dedup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f8e3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering the text\n",
    "\n",
    "tweets_df_fltr = tweets_df_dedup.copy()\n",
    "\n",
    "def preprocessor(text):\n",
    "    #text = re.sub('[http:,https:]','',text)\n",
    "    text = re.sub('[^a-zA-Z]',' ',text)\n",
    "    text = text.lower()\n",
    "    text = text.strip()\n",
    "    text = ''.join([i for i in text if i in string.ascii_lowercase+' '])\n",
    "    text = ' '.join([word for word in text.split() if word.isalnum()])\n",
    "    text = ' '.join([WordNetLemmatizer().lemmatize(word,pos='v') for word in text.split()])    \n",
    "    #text = ' '.join([PorterStemmer().stem(word) for word in text.split()])\n",
    "    text = ' '.join([word for word in text.split() if word not in stopwords.words('english')])\n",
    "    #text = ' '.join([word for word in text.split() if len(word)>3])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcab86bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df_fltr['text'] = tweets_df_dedup['text'].apply(preprocessor)\n",
    "\n",
    "\n",
    "tweets_df_fltr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439fd757",
   "metadata": {},
   "outputs": [],
   "source": [
    "porter=PorterStemmer()\n",
    "\n",
    "def tokenizer_porter(text):\n",
    "    return [porter.stem(word) for word in text.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad178559",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf=TfidfVectorizer(strip_accents=None,lowercase=False,preprocessor=None,tokenizer=tokenizer_porter,use_idf=True,norm='l2',smooth_idf=True)\n",
    "label=tweets_df_fltr[target].values\n",
    "features=tfidf.fit_transform(tweets_df_fltr.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d9b8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e03980",
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775059f5",
   "metadata": {},
   "source": [
    "### 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4405466",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us first analyze the distribution of the target variable\n",
    "\n",
    "print('\\033[1mTarget Variable Distribution'.center(55))\n",
    "plt.pie(tweets_df_fltr[target].value_counts(), labels=['Neutral','Positive','Negative'], counterclock=False, shadow=True, \n",
    "        explode=[0,0,0.1], autopct='%1.1f%%', radius=1.5, startangle=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d48477e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the average text sequence length\n",
    "\n",
    "tweets_df_rl = tweets_df_fltr.copy()\n",
    "tweets_df_rl['review_length'] = 0\n",
    "\n",
    "\n",
    "tweets_df_rl['review_length'] = tweets_df_rl['text'].apply(lambda x: len(x))\n",
    "\n",
    "plt.figure(figsize=[20,8])\n",
    "sns.boxplot(x=label,y='review_length', data=tweets_df_rl, hue=label,palette=['red','limegreen','cyan'])\n",
    "plt.title('Text Sequence Length')\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"Length of reviews\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d8bce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "neut_df = original_df[original_df[target]=='neutral']['text']\n",
    "pos_df = original_df[original_df[target]=='positive']['text']\n",
    "\n",
    "neg_df = original_df[original_df[target]== 'negative']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a30bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_text(text_df):\n",
    "\n",
    "    combi_text=\"\"\n",
    "    for x in text_df.values:\n",
    "        combi_text+=' '.join(x.split())\n",
    "    combi_text  = [x for x in combi_text.split() if len(x) >3 and x not in stopwords.words('english')]  \n",
    "    return combi_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bf244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_df(text_count_df,senti):\n",
    "    fredis = nltk.FreqDist(neut_text)\n",
    "    fredis_df = pd.DataFrame({senti: list(fredis.keys()),\n",
    "                      'Count': list(fredis.values())})\n",
    "    fredis_df = fredis_df.sort_values(by='Count',ascending=False)\n",
    "    return fredis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a564526a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_freq_dis(text_count_df,senti):\n",
    "    sns.barplot(data=text_count_df[:10],x=senti,y='Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af284286",
   "metadata": {},
   "outputs": [],
   "source": [
    "neut_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240ccd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "neut_df = neut_df.apply(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dc6ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "senti ='Neutral'\n",
    "neut_text = freq_text(neut_df)\n",
    "neut_frq_df = freq_df(neut_text,senti)\n",
    "plot_freq_dis(neut_frq_df,senti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91349bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9668f99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df = pos_df.apply(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb807aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "senti ='Positive'\n",
    "pos_df_text = freq_text(pos_df)\n",
    "pos_frq_df = freq_df(pos_df_text,senti)\n",
    "plot_freq_dis(pos_frq_df,senti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3347b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3607e1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_df = neg_df.apply(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aab6a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "senti ='Negative'\n",
    "neut_text = freq_text(neg_df)\n",
    "neut_frq_df = freq_df(neut_text,senti)\n",
    "plot_freq_dis(neut_frq_df,senti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b7209c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordcloud_draw(data, color, s):\n",
    "    words = ' '.join(data)\n",
    "    cleaned_word = \" \".join([word for word in words.split() if(word!='movie' and word!='film')])\n",
    "    wordcloud = WordCloud(stopwords=stopwords.words('english'),background_color=color,width=2500,height=2000).generate(cleaned_word)\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.title(s)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d25bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[20,10])\n",
    "plt.subplot(1,3,1)\n",
    "wordcloud_draw(neut_df,'navy','Frequently used neutral words')\n",
    "plt.subplot(1,3,2)\n",
    "wordcloud_draw(pos_df,'coral','Frequently used postive words')\n",
    "plt.subplot(1,3,3)\n",
    "wordcloud_draw(neg_df, 'limegreen','Frequently used negative words')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ba6c39",
   "metadata": {},
   "source": [
    "### 4. Predictive Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6db83c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning labels to target variable\n",
    "\n",
    "label_mapping={'negative':0, 'neutral':1, 'positive':2}\n",
    "tweets_df_fltr['sentiment'] = tweets_df_fltr['sentiment'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b087c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data intro training & testing sets\n",
    "\n",
    "X = features\n",
    "y = pd.Series(label).map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4ac023",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state=0)\n",
    "\n",
    "print('Original set  ---> ','feature size: ',X.shape,'label size',len(y))\n",
    "print('Training set  ---> ','feature size: ',X_train.shape,'label size',len(y_train))\n",
    "print('Testing set   ---> ','feature size: ',X_test.shape,'label size',len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b673356",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us create first create a table to store the results of various models \n",
    "\n",
    "result_df = pd.DataFrame(columns=['Models','Accuracy', 'Precision','Recall','F1-score','AUC-ROC score'])\n",
    "result_df['Models']=['Logistic Regression (LR)','Decision Tree Classifier (DT)','Random Forest Classifier (RF)','Naïve Bayes Classifier (NB)']\n",
    "result_df.fillna(0.0,inplace=True)\n",
    "result_df.set_index('Models',inplace=True)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d49afcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.loc['Logistic Regression (LR)','Accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfff088",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification Summary Function\n",
    "def classification_summary(pred,pred_prob,model):\n",
    "    result_df.loc[model,'Accuracy']   =round(accuracy_score(y_test,pred),3)*100   \n",
    "    result_df.loc[model,'Precision']=round(precision_score(y_test, pred, average='weighted'),3)*100 #, average='weighted'\n",
    "    result_df.loc[model,'Recall']=round(recall_score(y_test, pred, average='weighted'),3)*100 #, average='weighted'\n",
    "    result_df.loc[model,'F1-score']=round(f1_score(y_test, pred, average='weighted'),3)*100 #, average='weighted'\n",
    "    result_df.loc[model,'AUC-ROC score']=round(roc_auc_score(y_test, pred_prob, multi_class='ovr'),3)*100 #, multi_class='ovr'\n",
    "    \n",
    "    print('{}{}\\033[1m Evaluating {} \\033[0m{}{}\\n'.format('<'*3,'-'*35,model, '-'*35,'>'*3))\n",
    "    print('Accuracy = {}%'.format(round(accuracy_score(y_test, pred),3)*100))\n",
    "    print('F1 Score = {}%'.format(round(f1_score(y_test, pred, average='weighted'),3)*100)) #, average='weighted'\n",
    "    print('Precision Score = {}%'.format(round(precision_score(y_test, pred, average='weighted'),3)*100))\n",
    "    print('Recall Score = {}%'.format(round(recall_score(y_test, pred, average='weighted'),3)*100))\n",
    "    print('\\n \\033[1mConfusiton Matrix:\\033[0m\\n',confusion_matrix(y_test, pred))\n",
    "    print('\\n\\033[1mClassification Report:\\033[0m\\n',classification_report(y_test, pred))\n",
    "    \n",
    "    auc_roc(y_test, pred_prob, curves=['each_class'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8ad3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualising Function\n",
    "def auc_roc_plot(y_test, pred):    \n",
    "    ref = [0 for _ in range(len(y_test))]\n",
    "    ref_auc = roc_auc_score(y_test, ref)\n",
    "    lr_auc = roc_auc_score(y_test, pred)\n",
    "\n",
    "    ns_fpr, ns_tpr, _ = roc_curve(y_test, ref)\n",
    "    lr_fpr, lr_tpr, _ = roc_curve(y_test, pred)\n",
    "\n",
    "    plt.plot(ns_fpr, ns_tpr, linestyle='=')\n",
    "    plt.plot(lr_fpr, lr_tpr, marker='*', label='AUC = {}'.format(round(roc_auc_score(y_test, pred)*100,2))) \n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee24a5b",
   "metadata": {},
   "source": [
    "#### 1.linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4833204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Logistic Regression Classifier\n",
    "\n",
    "log_reg_model = LogisticRegression()\n",
    "log_reg_model.fit(X_train, y_train)\n",
    "pred = log_reg_model.predict(X_test)\n",
    "pred_prob = log_reg_model.predict_proba(X_test)\n",
    "classification_summary(pred,pred_prob,'Logistic Regression (LR)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2d62c4",
   "metadata": {},
   "source": [
    "#### 2. Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bf706e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Decision Tree Classifier\n",
    "\n",
    "DT_model = DecisionTreeClassifier()\n",
    "DT_model.fit(X_train, y_train)\n",
    "pred = DT_model.predict(X_test)\n",
    "pred_prob = DT_model.predict_proba(X_test)\n",
    "classification_summary(pred,pred_prob,'Decision Tree Classifier (DT)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298a2c4d",
   "metadata": {},
   "source": [
    "#### 3.Random Forest Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa060e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Random Forest Classifier\n",
    "\n",
    "RF_model = RandomForestClassifier()\n",
    "RF_model.fit(X_train, y_train)\n",
    "pred = RF_model.predict(X_test)\n",
    "pred_prob = RF_model.predict_proba(X_test)\n",
    "classification_summary(pred,pred_prob,'Random Forest Classifier (RF)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5eb4ef",
   "metadata": {},
   "source": [
    "#### 4.Naive Bayes Classfier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f13e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Naive Bayes Classifier\n",
    "\n",
    "NB_model = BernoulliNB()\n",
    "NB_model.fit(X_train,y_train)\n",
    "pred = NB_model.predict(X_test)\n",
    "pred_prob = NB_model.predict_proba(X_test)\n",
    "classification_summary(pred,pred_prob,'Naïve Bayes Classifier (NB)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d1aff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Confusion-Matrix of all the predictive Models\n",
    "\n",
    "labels=['Positive','Negative']\n",
    "def plot_cm(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=np.unique(y_true))\n",
    "    cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
    "    cm_perc = cm / cm_sum.astype(float) * 100\n",
    "    annot = np.empty_like(cm).astype(str)\n",
    "    nrows, ncols = cm.shape\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            c = cm[i, j]\n",
    "            p = cm_perc[i, j]\n",
    "            if i == j:\n",
    "                s = cm_sum[i]\n",
    "                annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
    "            elif c == 0:\n",
    "                annot[i, j] = ''\n",
    "            else:\n",
    "                annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
    "    cm = pd.DataFrame(cm, index=np.unique(y_true), columns=np.unique(y_true))\n",
    "    cm.columns=labels\n",
    "    cm.index=labels\n",
    "    cm.index.name = 'Actual'\n",
    "    cm.columns.name = 'Predicted'\n",
    "    #fig, ax = plt.subplots()\n",
    "    sns.heatmap(cm, annot=annot, fmt='')# cmap= \"GnBu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00828b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_mat_plot(all_models):\n",
    "    plt.figure(figsize=[20,3*math.ceil(1+len([all_models])/4)])\n",
    "    \n",
    "    for i in range(len(all_models)):\n",
    "        if len(labels)<=4:\n",
    "            plt.subplot(1,4,i+1)\n",
    "        else:\n",
    "            plt.subplot(math.ceil(len(all_models)/2),2,i+1)\n",
    "        pred = all_models[i].predict(X_test)\n",
    "        #plot_cm(Test_Y, pred)\n",
    "        sns.heatmap(confusion_matrix(y_test, pred), annot=True, fmt='.0f') #vmin=0,vmax=5,cmap='BuGn'\n",
    "        plt.title(result_df.index[i])\n",
    "        plt.yticks([0,1,2],labels=['Predicted Negative','Predicted Netural','Predicted Positive'],rotation=45)\n",
    "        plt.xticks([0,1,2],labels=['Actual Negative','Actual Netural','Actual Positive'],rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e0fab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat_plot([log_reg_model,DT_model,RF_model,NB_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b00a0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing all the models Scores\n",
    "\n",
    "plt.figure(figsize=[12,5])\n",
    "sns.heatmap(result_df, annot=True, vmin=40, vmax=100.0, cmap='RdYlBu', fmt='.1f')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30f2ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "    'n_estimators': [100,200,300,500],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'max_depth' : [1,2,4,5,6,7,8],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fd6d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_rfc = GridSearchCV(estimator=RF_model, param_grid=param_grid, cv= 5,n_jobs=-1)\n",
    "CV_rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb13164",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec3fccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_model_cv=RandomForestClassifier(random_state=42,**CV_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47fe589",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_model_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4231aeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat_plot([RF_model_cv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808516b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = RF_model_cv.predict(X_test)\n",
    "pred_prob = RF_model_cv.predict_proba(X_test)\n",
    "print(classification_report(y_test,pred))\n",
    "accuracy_score(y_test,pred)\n",
    "print(round(roc_auc_score(y_test, pred_prob, multi_class='ovr'),3)*100)\n",
    "auc_roc(y_test,pred_prob)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
